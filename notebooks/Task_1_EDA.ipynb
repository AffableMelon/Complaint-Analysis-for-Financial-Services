{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f41564",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data\n",
    "\n",
    "Load the raw dataset to understand its initial structure and volume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51ad6ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m.path.exists(RAW_DATA_PATH):\n\u001b[32m      2\u001b[39m     df_raw = pd.read_csv(RAW_DATA_PATH)\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRaw data loaded. Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_raw.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "if os.path.exists(RAW_DATA_PATH):\n",
    "    df_raw = pd.read_csv(RAW_DATA_PATH)\n",
    "    print(f\"Raw data loaded. Shape: {df_raw.shape}\")\n",
    "    display(df_raw.head(3))\n",
    "else:\n",
    "    print(f\"Raw data not found at {RAW_DATA_PATH}. Please ensure the file exists.\")\n",
    "    df_raw = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1886d8da",
   "metadata": {},
   "source": [
    "## 2. Quantify Missing Narratives\n",
    "\n",
    "A critical step is identifying how many complaints actually contain a narrative text, as this is the core input for our RAG system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_raw.empty:\n",
    "    total_complaints = len(df_raw)\n",
    "    missing_narratives = df_raw['Consumer complaint narrative'].isna().sum()\n",
    "    present_narratives = total_complaints - missing_narratives\n",
    "    \n",
    "    print(f\"Total Complaints: {total_complaints}\")\n",
    "    print(f\"Missing Narratives: {missing_narratives} ({missing_narratives/total_complaints:.1%})\")\n",
    "    print(f\"Usable Narratives: {present_narratives} ({present_narratives/total_complaints:.1%})\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(['Missing Narrative', 'Has Narrative'], [missing_narratives, present_narratives], color=['red', 'green'])\n",
    "    plt.title(\"Availability of Consumer Complaint Narratives\")\n",
    "    plt.ylabel(\"Number of Complaints\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7848dc3",
   "metadata": {},
   "source": [
    "## 3. Define Preprocessing Functions\n",
    "\n",
    "We define the logic to filter for the four target products and clean the text.\n",
    "Target Products:\n",
    "1. Credit card\n",
    "2. Personal loan\n",
    "3. Savings account\n",
    "4. Money transfers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Cleans the text narrative.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"xxxx\", \"\") # Remove redaction placeholders\n",
    "    text = \" \".join(text.split()) # Normalize whitespace\n",
    "    return text\n",
    "\n",
    "def process_complaints(df):\n",
    "    \"\"\"Filters and cleans the complaint dataset.\"\"\"\n",
    "    # Product Mapping\n",
    "    product_map = {\n",
    "        \"Credit card\": \"Credit card\",\n",
    "        \"Credit card or prepaid card\": \"Credit card\",\n",
    "        \"Prepaid card\": \"Credit card\",\n",
    "        \"Payday loan, title loan, or personal loan\": \"Personal loan\",\n",
    "        \"Personal loan\": \"Personal loan\",\n",
    "        \"Checking or savings account\": \"Savings account\",\n",
    "        \"Savings account\": \"Savings account\",\n",
    "        \"Money transfer, virtual currency, or money service\": \"Money transfers\",\n",
    "        \"Money transfers\": \"Money transfers\"\n",
    "    }\n",
    "    \n",
    "    # Create normalized product column\n",
    "    df['normalized_product'] = df['Product'].map(product_map)\n",
    "    \n",
    "    # Filter for target products (drop rows where map returned NaN)\n",
    "    df_filtered = df.dropna(subset=['normalized_product']).copy()\n",
    "    \n",
    "    # Filter for non-empty narratives\n",
    "    df_filtered = df_filtered.dropna(subset=['Consumer complaint narrative'])\n",
    "    \n",
    "    # Clean narratives\n",
    "    df_filtered['cleaned_narrative'] = df_filtered['Consumer complaint narrative'].apply(clean_text)\n",
    "    \n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eca70a",
   "metadata": {},
   "source": [
    "## 4. Apply Filtering and Preprocessing\n",
    "\n",
    "Apply the transformation to the raw data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ef861",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_raw.empty:\n",
    "    df_processed = process_complaints(df_raw)\n",
    "    print(f\"Processed Data Shape: {df_processed.shape}\")\n",
    "    display(df_processed.head(3))\n",
    "else:\n",
    "    df_processed = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287ff50",
   "metadata": {},
   "source": [
    "## 5. Visualize Target Product Distribution\n",
    "\n",
    "Analyze the distribution of complaints across the four specific product categories in the final dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d273a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_processed.empty:\n",
    "    product_counts = df_processed['normalized_product'].value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=product_counts.index, y=product_counts.values, palette=\"viridis\")\n",
    "    plt.title(\"Distribution of Complaints by Target Product\")\n",
    "    plt.xlabel(\"Product Category\")\n",
    "    plt.ylabel(\"Number of Complaints\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(product_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d79a44",
   "metadata": {},
   "source": [
    "## 6. Analyze Narrative Length Distributions\n",
    "\n",
    "Analyze the length of the complaints to understand the input size for our embedding model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_processed.empty:\n",
    "    # Calculate word count\n",
    "    df_processed['word_count'] = df_processed['cleaned_narrative'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "    print(\"Narrative Length Statistics:\")\n",
    "    print(df_processed['word_count'].describe())\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df_processed['word_count'], bins=50, kde=True, color='blue')\n",
    "    plt.title(\"Distribution of Complaint Narrative Lengths (Word Count)\")\n",
    "    plt.xlabel(\"Word Count\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab3d94e",
   "metadata": {},
   "source": [
    "## 7. Export Processed Data\n",
    "\n",
    "Save the final cleaned dataset to the specified path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85fa2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_processed.empty:\n",
    "    os.makedirs(os.path.dirname(PROCESSED_DATA_PATH), exist_ok=True)\n",
    "    df_processed.to_csv(PROCESSED_DATA_PATH, index=False)\n",
    "    print(f\"Successfully saved processed data to {PROCESSED_DATA_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
